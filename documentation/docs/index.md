# ACE2 - Core System

This documentation is a work in progress coinciding with the development of the **ACE2 Core System**. The ACE2 core system is _the_ core component of a complete re-write of the **Analysis Correlation Engine (ACE)**. Allow for imperfections as various sections of the documentation can be somewhere between pseudo code and proper documentation.

This is what is in mind:

```python

from ace.analysis import RootAnalysis
from ace.modules.threaded import initialize_modules
from ace.system.threaded import initialize_system

initialize_system()
modules = initialize_modules()
modules.register()
modules.start()

root = RootAnalysis(description="Example")
observable = root.add_observable('ipv4', '1.2.3.4')
root.submit()

root.wait()
print(root)

```

## Fundamentals

ACE is fundamentally *the analysis of observations*. You have *observables*, which are the things you have observed, and then you have the *analysis* of those observables, which may in turn produce additional observables that need to be analyzed.

The process is recursive until all observations have been analyzed.

ACE is a system that provides this simple analysis capability.

## System Design Overview

ACE is split up into three pieces: *core system*, *analysis modules*, and *alert management*. Each system can operate on its own, independent of each other. They can (and do) communicate with each other through defined interfaces.

### Analysis Module Overview

An **analysis module** takes an observable as input, generates analysis results, and may produce zero or more observables as output. ACE can support any number of analysis modules in any programming language.

### Core System Overview

The **core system** is responsible for tracking analysis requests/results, storing file content, maintaining a result cache, and other required operations.

The core system is itself composed of individual systems that are simple to extend to provide additional functionality.

### Alert Management Overview

The **alert management system** receives alert tracking requests from the core system and tracks them over the lifetime of the alert. It provides tooling around alerts, as well as a graphical user interface for analysts to review and disposition the alerts.

## Core System Details

The core system is composed of multiple *abstract interfaces*, which can each be implemented in any manner required. These core system interfaces are listed below.

- alerting: provides an interface to send an alert to the alert management system
- analysis tracking: keeps track of root analysis data and analysis details
- caching: keeps a cache of recent analysis results
- configuration: provides a way to read and write configuration data
- events: provides a way to subscribe to events generated by the core system
- locking: provides a global locking system to provide concurrency
- module tracking: keeps track of registered analysis modules
- request tracking: keeps track of analysis requests
- storage: provides a generic interface to read and write arbitrary binary data
- work queue: provides an interface for analysis modules to receive analysis requests

Each interface is defined in `ace.system.*` Each abstract interface function is wrapped by an importable function that may provide additional functionality, error checking, or simplification for use.

### Core System Initialization

The first step is to provide a running core system that implements all the interfaces listed above.

### Analysis Module Registration

Once the core system is running, analysis modules must then register themselves to the system. This is accomplished by calling the `register_analysis_module_type` function.

An analysis module type defines what requirements and restrictions are around certain kinds of observables that the analysis module will accept. The most simple and common requirement is providing a list of one or more observable types the module supports. The core system will only generate analysis requests for observables that match the given type(s). A more complex example might be an analysis module that depends on another analysis module, in which case, ACE would not submit an analysis request until the dependency is met.

Analysis modules also register under specific versions. The core system keeps track of the registration data.

Finally, each module asks the core system for the next analysis request to process by calling the `get_next_analysis_request` function, which blocks until work is available or the analysis reaches time out.

### Root Analysis Request Processing

New analysis requests are submitted to the core system by submitting a **root analysis request**. The analysis is tracked, and new *observable analysis requests* are generated for each observable that requires analysis by any registered analysis module. These requests are placed into the work queues assigned to each analysis module type. The requests are then picked up by the analysis modules through these queues.

### Analysis Result Processing

Analysis modules post the results of the analysis by submitting an *observable analysis result*, which includes both the original request, as well as the results of the analysis.

The *difference* between the original request and the generated analysis is computed. Then the difference is applied to the tracked analysis objects.

Any additional observations are analyzed as before, generating new observable analysis requests. This process continues until all analysis modules have completed analysis for all observables they accept.

### Alerting

Any root analysis that has one or more detection points is submitted to the alert management system. This can occur multiple times for the same root analysis.

### Analysis Result Cache

The result of the analysis of an observation can be *cached* if an analysis module is registered with a time-to-live value set for the cache. If the module types has this value, then it looks up results in the cache *before* making any analysis requests. This prevents duplicate analysis work in the cases where the results can be cached.

### Storage

ACE provides a very generic way to store any binary content. Data is stored as binary and referenced by sha256 hash. All data is associated to a root analysis. Any data that is no longer referenced automatically expires after some configurable time.

### Locking

ACE provides a generic way to obtain a lock on anything that can be identified by a simple string. Locks:

- are reentrant
- are distributed
- have time outs

The core system uses the **locking** capability extensively to provide concurrency between all the different interfaces.

### Work Queues

When a new analysis module type is registered, a new **work queue** is created for that type. When the core system generates analysis requests for that type, those requests are sent to the work queue. The external analysis module instances then acquire these analysis requests through the work queue.

A single analysis request cannot be acquired by multiple analysis module instances. The queues are FIFO.

## Workflow Example

This walks you through a really simple example of pretending to analyze an observable of type "test." Note that we are showing pseudo code for different components of ACE.

Also, observe that we never actually assume the role of the core system because the core system simply responds to and processes requests from the other systems.


```python
# assume this initializes a core system
initialize_system()

# 
# assume the role of analysis module first
# ----------------------------------------

# register a basic analysis module
# in this case we register an analysis module of type "test" which accepts observables of type "test"
amt = AnalysisModuleType("test", "this is a test analysis module", ['test'])
register_analysis_module_type(amt)

# 
# assume the role of something that collects stuff to analyze
# -----------------------------------------------------------

# create a new root analysis as our analysis "container"
root = RootAnalysis()
# add a new observable with type "type" and value "test"
observable = root.add_observable("test", "test")
# submit the root for analysis to the core system
process_analysis_request(root.create_analysis_request())

# at this point the core system has taken the request and generated
# a new observable analysis request which is placed in the work queue for analysis module type "test"

#
# assume the role of the analysis module
# --------------------------------------

# first we create an identity
# this is just some unique name that identifies the *instance* of the executing analysis module
owner_uuid = "test host localhost pid 12343 tid 12343353"

# receive the next work item
# the format is get_next_analysis_request(who_you_are, which_analysis_module_type, how_long_to_wait)
request = get_next_analysis_request(owner_uuid, amt, 0)

# pretend to analyze it by generating details
analysis_details = {"test": "result"}
request.result = request.create_result()
request.result.observable.add_analysis(type=amt, details=analysis_details)

# submit the result of the analysis to the core system
process_analysis_request(request)

#
# at this point the analysis is complete because we did not add an additional observables
#

```
