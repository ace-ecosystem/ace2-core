{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ACE2 - Core System \u00b6 This documentation is a work in progress coinciding with the development of the ACE2 Core System . The ACE2 core system is the core component of a complete re-write of the Analysis Correlation Engine (ACE) . Allow for imperfections as various sections of the documentation can be somewhere between pseudo code and proper documentation. This is what is in mind: from ace.analysis import RootAnalysis from ace.modules.threaded import initialize_modules from ace.system.threaded import initialize_system initialize_system() modules = initialize_modules() modules.register() modules.start() root = RootAnalysis(description=\"Example\") observable = root.add_observable('ipv4', '1.2.3.4') root.submit() root.wait() print(root) Fundamentals \u00b6 ACE is fundamentally the analysis of observations . You have observables , which are the things you have observed, and then you have the analysis of those observables, which may in turn produce additional observables that need to be analyzed. The process is recursive until all observations have been analyzed. ACE is a system that provides this simple analysis capability. System Design Overview \u00b6 ACE is split up into three pieces: core system , analysis modules , and alert management . Each system can operate on its own, independent of each other. They can (and do) communicate with each other through defined interfaces. Analysis Module Overview \u00b6 An analysis module takes an observable as input, generates analysis results, and may produce zero or more observables as output. ACE can support any number of analysis modules in any programming language. Core System Overview \u00b6 The core system is responsible for tracking analysis requests/results, storing file content, maintaining a result cache, and other required operations. The core system is itself composed of individual systems that are simple to extend to provide additional functionality. Alert Management Overview \u00b6 The alert management system receives alert tracking requests from the core system and tracks them over the lifetime of the alert. It provides tooling around alerts, as well as a graphical user interface for analysts to review and disposition the alerts. Core System Details \u00b6 The core system is composed of multiple abstract interfaces , which can each be implemented in any manner required. These core system interfaces are listed below. alerting: provides an interface to send an alert to the alert management system analysis tracking: keeps track of root analysis data and analysis details caching: keeps a cache of recent analysis results configuration: provides a way to read and write configuration data events: provides a way to subscribe to events generated by the core system locking: provides a global locking system to provide concurrency module tracking: keeps track of registered analysis modules request tracking: keeps track of analysis requests storage: provides a generic interface to read and write arbitrary binary data work queue: provides an interface for analysis modules to receive analysis requests Each interface is defined in ace.system.* Each abstract interface function is wrapped by an importable function that may provide additional functionality, error checking, or simplification for use. Core System Initialization \u00b6 The first step is to provide a running core system that implements all the interfaces listed above. Analysis Module Registration \u00b6 Once the core system is running, analysis modules must then register themselves to the system. This is accomplished by calling the register_analysis_module_type function. An analysis module type defines what requirements and restrictions are around certain kinds of observables that the analysis module will accept. The most simple and common requirement is providing a list of one or more observable types the module supports. The core system will only generate analysis requests for observables that match the given type(s). A more complex example might be an analysis module that depends on another analysis module, in which case, ACE would not submit an analysis request until the dependency is met. Analysis modules also register under specific versions. The core system keeps track of the registration data. Finally, each module asks the core system for the next analysis request to process by calling the get_next_analysis_request function, which blocks until work is available or the analysis reaches time out. Root Analysis Request Processing \u00b6 New analysis requests are submitted to the core system by submitting a root analysis request . The analysis is tracked, and new observable analysis requests are generated for each observable that requires analysis by any registered analysis module. These requests are placed into the work queues assigned to each analysis module type. The requests are then picked up by the analysis modules through these queues. Analysis Result Processing \u00b6 Analysis modules post the results of the analysis by submitting an observable analysis result , which includes both the original request, as well as the results of the analysis. The difference between the original request and the generated analysis is computed. Then the difference is applied to the tracked analysis objects. Any additional observations are analyzed as before, generating new observable analysis requests. This process continues until all analysis modules have completed analysis for all observables they accept. Alerting \u00b6 Any root analysis that has one or more detection points is submitted to the alert management system. This can occur multiple times for the same root analysis. Analysis Result Cache \u00b6 The result of the analysis of an observation can be cached if an analysis module is registered with a time-to-live value set for the cache. If the module types has this value, then it looks up results in the cache before making any analysis requests. This prevents duplicate analysis work in the cases where the results can be cached. Storage \u00b6 ACE provides a very generic way to store any binary content. Data is stored as binary and referenced by sha256 hash. All data is associated to a root analysis. Any data that is no longer referenced automatically expires after some configurable time. Locking \u00b6 ACE provides a generic way to obtain a lock on anything that can be identified by a simple string. Locks: are reentrant are distributed have time outs The core system uses the locking capability extensively to provide concurrency between all the different interfaces. Work Queues \u00b6 When a new analysis module type is registered, a new work queue is created for that type. When the core system generates analysis requests for that type, those requests are sent to the work queue. The external analysis module instances then acquire these analysis requests through the work queue. A single analysis request cannot be acquired by multiple analysis module instances. The queues are FIFO. Workflow Example \u00b6 This walks you through a really simple example of pretending to analyze an observable of type \"test.\" Note that we are showing pseudo code for different components of ACE. Also, observe that we never actually assume the role of the core system because the core system simply responds to and processes requests from the other systems. # assume this initializes a core system initialize_system() # # assume the role of analysis module first # ---------------------------------------- # register a basic analysis module # in this case we register an analysis module of type \"test\" which accepts observables of type \"test\" amt = AnalysisModuleType(\"test\", \"this is a test analysis module\", ['test']) register_analysis_module_type(amt) # # assume the role of something that collects stuff to analyze # ----------------------------------------------------------- # create a new root analysis as our analysis \"container\" root = RootAnalysis() # add a new observable with type \"type\" and value \"test\" observable = root.add_observable(\"test\", \"test\") # submit the root for analysis to the core system process_analysis_request(root.create_analysis_request()) # at this point the core system has taken the request and generated # a new observable analysis request which is placed in the work queue for analysis module type \"test\" # # assume the role of the analysis module # -------------------------------------- # first we create an identity # this is just some unique name that identifies the *instance* of the executing analysis module owner_uuid = \"test host localhost pid 12343 tid 12343353\" # receive the next work item # the format is get_next_analysis_request(who_you_are, which_analysis_module_type, how_long_to_wait) request = get_next_analysis_request(owner_uuid, amt, 0) # pretend to analyze it by generating details analysis_details = {\"test\": \"result\"} request.result = request.create_result() request.result.observable.add_analysis(type=amt, details=analysis_details) # submit the result of the analysis to the core system process_analysis_request(request) # # at this point the analysis is complete because we did not add an additional observables #","title":"ACE2 - Core System"},{"location":"#ace2-core-system","text":"This documentation is a work in progress coinciding with the development of the ACE2 Core System . The ACE2 core system is the core component of a complete re-write of the Analysis Correlation Engine (ACE) . Allow for imperfections as various sections of the documentation can be somewhere between pseudo code and proper documentation. This is what is in mind: from ace.analysis import RootAnalysis from ace.modules.threaded import initialize_modules from ace.system.threaded import initialize_system initialize_system() modules = initialize_modules() modules.register() modules.start() root = RootAnalysis(description=\"Example\") observable = root.add_observable('ipv4', '1.2.3.4') root.submit() root.wait() print(root)","title":"ACE2 - Core System"},{"location":"#fundamentals","text":"ACE is fundamentally the analysis of observations . You have observables , which are the things you have observed, and then you have the analysis of those observables, which may in turn produce additional observables that need to be analyzed. The process is recursive until all observations have been analyzed. ACE is a system that provides this simple analysis capability.","title":"Fundamentals"},{"location":"#system-design-overview","text":"ACE is split up into three pieces: core system , analysis modules , and alert management . Each system can operate on its own, independent of each other. They can (and do) communicate with each other through defined interfaces.","title":"System Design Overview"},{"location":"#analysis-module-overview","text":"An analysis module takes an observable as input, generates analysis results, and may produce zero or more observables as output. ACE can support any number of analysis modules in any programming language.","title":"Analysis Module Overview"},{"location":"#core-system-overview","text":"The core system is responsible for tracking analysis requests/results, storing file content, maintaining a result cache, and other required operations. The core system is itself composed of individual systems that are simple to extend to provide additional functionality.","title":"Core System Overview"},{"location":"#alert-management-overview","text":"The alert management system receives alert tracking requests from the core system and tracks them over the lifetime of the alert. It provides tooling around alerts, as well as a graphical user interface for analysts to review and disposition the alerts.","title":"Alert Management Overview"},{"location":"#core-system-details","text":"The core system is composed of multiple abstract interfaces , which can each be implemented in any manner required. These core system interfaces are listed below. alerting: provides an interface to send an alert to the alert management system analysis tracking: keeps track of root analysis data and analysis details caching: keeps a cache of recent analysis results configuration: provides a way to read and write configuration data events: provides a way to subscribe to events generated by the core system locking: provides a global locking system to provide concurrency module tracking: keeps track of registered analysis modules request tracking: keeps track of analysis requests storage: provides a generic interface to read and write arbitrary binary data work queue: provides an interface for analysis modules to receive analysis requests Each interface is defined in ace.system.* Each abstract interface function is wrapped by an importable function that may provide additional functionality, error checking, or simplification for use.","title":"Core System Details"},{"location":"#core-system-initialization","text":"The first step is to provide a running core system that implements all the interfaces listed above.","title":"Core System Initialization"},{"location":"#analysis-module-registration","text":"Once the core system is running, analysis modules must then register themselves to the system. This is accomplished by calling the register_analysis_module_type function. An analysis module type defines what requirements and restrictions are around certain kinds of observables that the analysis module will accept. The most simple and common requirement is providing a list of one or more observable types the module supports. The core system will only generate analysis requests for observables that match the given type(s). A more complex example might be an analysis module that depends on another analysis module, in which case, ACE would not submit an analysis request until the dependency is met. Analysis modules also register under specific versions. The core system keeps track of the registration data. Finally, each module asks the core system for the next analysis request to process by calling the get_next_analysis_request function, which blocks until work is available or the analysis reaches time out.","title":"Analysis Module Registration"},{"location":"#root-analysis-request-processing","text":"New analysis requests are submitted to the core system by submitting a root analysis request . The analysis is tracked, and new observable analysis requests are generated for each observable that requires analysis by any registered analysis module. These requests are placed into the work queues assigned to each analysis module type. The requests are then picked up by the analysis modules through these queues.","title":"Root Analysis Request Processing"},{"location":"#analysis-result-processing","text":"Analysis modules post the results of the analysis by submitting an observable analysis result , which includes both the original request, as well as the results of the analysis. The difference between the original request and the generated analysis is computed. Then the difference is applied to the tracked analysis objects. Any additional observations are analyzed as before, generating new observable analysis requests. This process continues until all analysis modules have completed analysis for all observables they accept.","title":"Analysis Result Processing"},{"location":"#alerting","text":"Any root analysis that has one or more detection points is submitted to the alert management system. This can occur multiple times for the same root analysis.","title":"Alerting"},{"location":"#analysis-result-cache","text":"The result of the analysis of an observation can be cached if an analysis module is registered with a time-to-live value set for the cache. If the module types has this value, then it looks up results in the cache before making any analysis requests. This prevents duplicate analysis work in the cases where the results can be cached.","title":"Analysis Result Cache"},{"location":"#storage","text":"ACE provides a very generic way to store any binary content. Data is stored as binary and referenced by sha256 hash. All data is associated to a root analysis. Any data that is no longer referenced automatically expires after some configurable time.","title":"Storage"},{"location":"#locking","text":"ACE provides a generic way to obtain a lock on anything that can be identified by a simple string. Locks: are reentrant are distributed have time outs The core system uses the locking capability extensively to provide concurrency between all the different interfaces.","title":"Locking"},{"location":"#work-queues","text":"When a new analysis module type is registered, a new work queue is created for that type. When the core system generates analysis requests for that type, those requests are sent to the work queue. The external analysis module instances then acquire these analysis requests through the work queue. A single analysis request cannot be acquired by multiple analysis module instances. The queues are FIFO.","title":"Work Queues"},{"location":"#workflow-example","text":"This walks you through a really simple example of pretending to analyze an observable of type \"test.\" Note that we are showing pseudo code for different components of ACE. Also, observe that we never actually assume the role of the core system because the core system simply responds to and processes requests from the other systems. # assume this initializes a core system initialize_system() # # assume the role of analysis module first # ---------------------------------------- # register a basic analysis module # in this case we register an analysis module of type \"test\" which accepts observables of type \"test\" amt = AnalysisModuleType(\"test\", \"this is a test analysis module\", ['test']) register_analysis_module_type(amt) # # assume the role of something that collects stuff to analyze # ----------------------------------------------------------- # create a new root analysis as our analysis \"container\" root = RootAnalysis() # add a new observable with type \"type\" and value \"test\" observable = root.add_observable(\"test\", \"test\") # submit the root for analysis to the core system process_analysis_request(root.create_analysis_request()) # at this point the core system has taken the request and generated # a new observable analysis request which is placed in the work queue for analysis module type \"test\" # # assume the role of the analysis module # -------------------------------------- # first we create an identity # this is just some unique name that identifies the *instance* of the executing analysis module owner_uuid = \"test host localhost pid 12343 tid 12343353\" # receive the next work item # the format is get_next_analysis_request(who_you_are, which_analysis_module_type, how_long_to_wait) request = get_next_analysis_request(owner_uuid, amt, 0) # pretend to analyze it by generating details analysis_details = {\"test\": \"result\"} request.result = request.create_result() request.result.observable.add_analysis(type=amt, details=analysis_details) # submit the result of the analysis to the core system process_analysis_request(request) # # at this point the analysis is complete because we did not add an additional observables #","title":"Workflow Example"},{"location":"core/","text":"Core System \u00b6 ACE is composed of subsystem component interfaces. Each interface allows implementation of a particular part of the system. An implementation of all of these interfaces would create a complete ACE core system . System Interfaces \u00b6 The following interfaces make up the entirety of the ACE system: Alerting Analysis Tracking Caching Configuration Events Locking Analysis Module Tracking Observables Analysis Request Tracking Storage Work Queues Process Workflow \u00b6 Overview \u00b6 The following is a basic high level overview of the fundamental logic of the analysis system: Register one or more analysis modules. Submit a new analysis request. New analysis requests are added to the work queues based on the content of the submission. Analysis modules pull requests from the work queues. Analysis modules post results of the analysis. New analysis requests are added to the work queues based on the content of the posted results. Process continues until work queues are emptied. Analysis Module Registration \u00b6 The process begins by registering one or more analysis modules . A module registration informs the system what type of data the module is interested in analyzing. A registered analysis module is registered under a type name and each analysis module type is assigned its own work queue that receives analysis requests specific to that module type . This part of the process is external to the core system. Analysis Request Submission \u00b6 Work is initiated by submitting a root analysis request to the system. An initial request supplies the root analysis object along with any observables that should be analyzed by the system. Analysis Request Processing \u00b6 The ACE core system processes inbound analysis requests by enumerating all observables in the root analysis object and cross-referencing that with all registered analysis modules . An observable is assigned to a module for analysis by creating a new observable analysis request and appending that request to the work queue assigned to that analysis module type. Analysis modules then receive the request by acquiring the next work item from their assigned work queues . Analysis Module Execution \u00b6 Each analysis module receives observable analysis requests through the work queue which is assigned to the analysis module type . The execution of the analysis module logic is external to the core engine. Analysis Result Processing \u00b6 The results of the analysis are posted back to the ACE core system as observable analysis results . These results contain the original request as well as the result of the analysis. The ACE core system applies any changes generated by the analysis back to the root analysis object. Any new observables found in the results generate new analysis requests if they have not yet been analyzed. This recursion continues until all observables have been analyzed by all registered analysis modules. Alerting \u00b6 At any point during processing any root analysis that has one or more detection points is automatically passed to the alert interface for processing.","title":"Core System"},{"location":"core/#core-system","text":"ACE is composed of subsystem component interfaces. Each interface allows implementation of a particular part of the system. An implementation of all of these interfaces would create a complete ACE core system .","title":"Core System"},{"location":"core/#system-interfaces","text":"The following interfaces make up the entirety of the ACE system: Alerting Analysis Tracking Caching Configuration Events Locking Analysis Module Tracking Observables Analysis Request Tracking Storage Work Queues","title":"System Interfaces"},{"location":"core/#process-workflow","text":"","title":"Process Workflow"},{"location":"core/#overview","text":"The following is a basic high level overview of the fundamental logic of the analysis system: Register one or more analysis modules. Submit a new analysis request. New analysis requests are added to the work queues based on the content of the submission. Analysis modules pull requests from the work queues. Analysis modules post results of the analysis. New analysis requests are added to the work queues based on the content of the posted results. Process continues until work queues are emptied.","title":"Overview"},{"location":"core/#analysis-module-registration","text":"The process begins by registering one or more analysis modules . A module registration informs the system what type of data the module is interested in analyzing. A registered analysis module is registered under a type name and each analysis module type is assigned its own work queue that receives analysis requests specific to that module type . This part of the process is external to the core system.","title":"Analysis Module Registration"},{"location":"core/#analysis-request-submission","text":"Work is initiated by submitting a root analysis request to the system. An initial request supplies the root analysis object along with any observables that should be analyzed by the system.","title":"Analysis Request Submission"},{"location":"core/#analysis-request-processing","text":"The ACE core system processes inbound analysis requests by enumerating all observables in the root analysis object and cross-referencing that with all registered analysis modules . An observable is assigned to a module for analysis by creating a new observable analysis request and appending that request to the work queue assigned to that analysis module type. Analysis modules then receive the request by acquiring the next work item from their assigned work queues .","title":"Analysis Request Processing"},{"location":"core/#analysis-module-execution","text":"Each analysis module receives observable analysis requests through the work queue which is assigned to the analysis module type . The execution of the analysis module logic is external to the core engine.","title":"Analysis Module Execution"},{"location":"core/#analysis-result-processing","text":"The results of the analysis are posted back to the ACE core system as observable analysis results . These results contain the original request as well as the result of the analysis. The ACE core system applies any changes generated by the analysis back to the root analysis object. Any new observables found in the results generate new analysis requests if they have not yet been analyzed. This recursion continues until all observables have been analyzed by all registered analysis modules.","title":"Analysis Result Processing"},{"location":"core/#alerting","text":"At any point during processing any root analysis that has one or more detection points is automatically passed to the alert interface for processing.","title":"Alerting"},{"location":"core/alerting/","text":"Alerting \u00b6 An alert is created when a root is found to contain one or more detection points when processing analysis requests. Alerts are tracked through the ace.system.alerting.AlertTrackingInterface .","title":"Alerting"},{"location":"core/alerting/#alerting","text":"An alert is created when a root is found to contain one or more detection points when processing analysis requests. Alerts are tracked through the ace.system.alerting.AlertTrackingInterface .","title":"Alerting"},{"location":"core/analysis_module_tracking/","text":"Analysis Module Tracking \u00b6 Analysis modules are tracked as analysis module types through the interface ace.system.analysis_module_tracking.AnalysisModuleTrackingInterface . Analysis modules start by registering with the system. Multiple instances of the same analysis module can register as long as the version of the module remains the same. This keeps track of what analysis modules have been registered and which ones have not expired or been invalidated. Each analysis module type is assigned a work queue. Any work created that the analysis module supports is assigned to the work queue. Any instance of the analysis module can pick up the work from the queue. When an analysis module requests work, it also submits its current version data so that it can be checked against the registered analysis module. Versions \u00b6 Every analysis module type has a version , which is defined by a number of properties. When an analysis module registers a new version, the new type replaces the old type. Any attempts to acquire work with the old version are denied.","title":"Analysis Module Tracking"},{"location":"core/analysis_module_tracking/#analysis-module-tracking","text":"Analysis modules are tracked as analysis module types through the interface ace.system.analysis_module_tracking.AnalysisModuleTrackingInterface . Analysis modules start by registering with the system. Multiple instances of the same analysis module can register as long as the version of the module remains the same. This keeps track of what analysis modules have been registered and which ones have not expired or been invalidated. Each analysis module type is assigned a work queue. Any work created that the analysis module supports is assigned to the work queue. Any instance of the analysis module can pick up the work from the queue. When an analysis module requests work, it also submits its current version data so that it can be checked against the registered analysis module.","title":"Analysis Module Tracking"},{"location":"core/analysis_module_tracking/#versions","text":"Every analysis module type has a version , which is defined by a number of properties. When an analysis module registers a new version, the new type replaces the old type. Any attempts to acquire work with the old version are denied.","title":"Versions"},{"location":"core/analysis_module_type/","text":"Analysis Module Type \u00b6 An analysis module type represents a type of analysis module that can be registered and used to analyze observables . The specification of the type determines: what observables it is interested in analyzing what other analysis modules it depends on how long to cache analysis results what version is accepted ACE supports any number of instances of a given analysis module type running concurrently.","title":"Analysis Module Type"},{"location":"core/analysis_module_type/#analysis-module-type","text":"An analysis module type represents a type of analysis module that can be registered and used to analyze observables . The specification of the type determines: what observables it is interested in analyzing what other analysis modules it depends on how long to cache analysis results what version is accepted ACE supports any number of instances of a given analysis module type running concurrently.","title":"Analysis Module Type"},{"location":"core/analysis_request_tracking/","text":"Analysis Request Tracking \u00b6 All requests to perform analysis are made through analysis request objects and tracked in the ace.system.analysis_request.AnalysisRequestTrackingInterface","title":"Analysis Request Tracking"},{"location":"core/analysis_request_tracking/#analysis-request-tracking","text":"All requests to perform analysis are made through analysis request objects and tracked in the ace.system.analysis_request.AnalysisRequestTrackingInterface","title":"Analysis Request Tracking"},{"location":"core/analysis_requests/","text":"Analysis Requests \u00b6 There are three types of analysis requests. Root Analysis Requests \u00b6 A root analysis request is one that contains only a root analysis object. If the root analysis object does not exist, it is added to the system and tracked . If the root analysis already exists, it is replaced by a copy of a new one that merges the new analysis into the old one. Observable Analysis Request \u00b6 An observable analysis request is one that contains both a root analysis object and an observable object, as well as a copy of the analysis module type that is supposed to analyze it. These requests are added to the work queues of their respective analysis module types. References to observable analysis requests are also tracked inside the observables themselves. Observable Analysis Result \u00b6 Analysis modules record analysis results inside of the requests they receive. In other words, the analysis results are appended to the original request. These observable analysis results are then resubmitted back to the core system for processing. The observable analysis result is an analysis request when it's resubmitted back to the core system for processing.","title":"Analysis Requests"},{"location":"core/analysis_requests/#analysis-requests","text":"There are three types of analysis requests.","title":"Analysis Requests"},{"location":"core/analysis_requests/#root-analysis-requests","text":"A root analysis request is one that contains only a root analysis object. If the root analysis object does not exist, it is added to the system and tracked . If the root analysis already exists, it is replaced by a copy of a new one that merges the new analysis into the old one.","title":"Root Analysis Requests"},{"location":"core/analysis_requests/#observable-analysis-request","text":"An observable analysis request is one that contains both a root analysis object and an observable object, as well as a copy of the analysis module type that is supposed to analyze it. These requests are added to the work queues of their respective analysis module types. References to observable analysis requests are also tracked inside the observables themselves.","title":"Observable Analysis Request"},{"location":"core/analysis_requests/#observable-analysis-result","text":"Analysis modules record analysis results inside of the requests they receive. In other words, the analysis results are appended to the original request. These observable analysis results are then resubmitted back to the core system for processing. The observable analysis result is an analysis request when it's resubmitted back to the core system for processing.","title":"Observable Analysis Result"},{"location":"core/analysis_tracking/","text":"Analysis Tracking \u00b6 Analysis data is tracked using the ace.system.analysis_tracking.AnalysisTrackingInterface . The interface tracks root analysis separately from the details of the analysis.","title":"Analysis Tracking"},{"location":"core/analysis_tracking/#analysis-tracking","text":"Analysis data is tracked using the ace.system.analysis_tracking.AnalysisTrackingInterface . The interface tracks root analysis separately from the details of the analysis.","title":"Analysis Tracking"},{"location":"core/caching/","text":"Caching \u00b6 The results of analysis work are returned as analysis requests . If the analysis module type supports caching then these analysis results are tracked by ace.system.caching.CacheInterface . The analysis result contains a copy of the root analysis and the observable as they existed before the analysis, as well as the modified version as they existed after the analysis. When an analysis is requested for an observable that has a cached result, the difference between the before and after copies of the root and observables are applied. Caching uses a cache key to index the cached analysis results. The key is generated from a combination of: the type of the observable the value of the observable the time of the observable (if available) the name of the analysis module type the version of the analysis module type optionally, any additional cache keys specified by the analysis module type If the cache key changes then the lookup changes. Cache results can be set to expire after a period of time as specified by the analysis module type.","title":"Caching"},{"location":"core/caching/#caching","text":"The results of analysis work are returned as analysis requests . If the analysis module type supports caching then these analysis results are tracked by ace.system.caching.CacheInterface . The analysis result contains a copy of the root analysis and the observable as they existed before the analysis, as well as the modified version as they existed after the analysis. When an analysis is requested for an observable that has a cached result, the difference between the before and after copies of the root and observables are applied. Caching uses a cache key to index the cached analysis results. The key is generated from a combination of: the type of the observable the value of the observable the time of the observable (if available) the name of the analysis module type the version of the analysis module type optionally, any additional cache keys specified by the analysis module type If the cache key changes then the lookup changes. Cache results can be set to expire after a period of time as specified by the analysis module type.","title":"Caching"},{"location":"core/locking/","text":"Locking \u00b6 ACE is a distributed system that requires synchronization between processes. This is accomplished by using the ace.system.locking.LockingInterface . Locks \u00b6 A lock is defined as an arbitrary string value. Typically, the value of a lock represents the name of something being locked. Once a lock is held, no other attempt to acquire the lock will succeed until it is released or the lock acquisition expires. Lock Ownership \u00b6 Every lock is made by and assigned to a lock owner . An owner is defined as an arbitrary string value. Typically, an owner value is made up of some combination of properties such as host name, process, and thread ids. This allows for identifying unique threads of execution. Deadlocks \u00b6 A lock owner can acquire multiple locks. If a lock owner attempts to acquire a lock that is already acquired by another owner, and that owner is waiting for the other to release a different lock, then a deadlock occurs. When a deadlock occurs, the request must be made again later.","title":"Locking"},{"location":"core/locking/#locking","text":"ACE is a distributed system that requires synchronization between processes. This is accomplished by using the ace.system.locking.LockingInterface .","title":"Locking"},{"location":"core/locking/#locks","text":"A lock is defined as an arbitrary string value. Typically, the value of a lock represents the name of something being locked. Once a lock is held, no other attempt to acquire the lock will succeed until it is released or the lock acquisition expires.","title":"Locks"},{"location":"core/locking/#lock-ownership","text":"Every lock is made by and assigned to a lock owner . An owner is defined as an arbitrary string value. Typically, an owner value is made up of some combination of properties such as host name, process, and thread ids. This allows for identifying unique threads of execution.","title":"Lock Ownership"},{"location":"core/locking/#deadlocks","text":"A lock owner can acquire multiple locks. If a lock owner attempts to acquire a lock that is already acquired by another owner, and that owner is waiting for the other to release a different lock, then a deadlock occurs. When a deadlock occurs, the request must be made again later.","title":"Deadlocks"},{"location":"core/storage/","text":"Storage \u00b6 The ace.system.storage.StorageInterface provides a way to store data such as files in an abstract way.","title":"Storage"},{"location":"core/storage/#storage","text":"The ace.system.storage.StorageInterface provides a way to store data such as files in an abstract way.","title":"Storage"},{"location":"core/work_queue/","text":"Work Queues \u00b6 A work queue is a queue created for each analysis module type registered with the system. These queues are filled with analysis requests that are generated when other analysis requests are processed by the system. Each analysis module type gets exactly one work queue associated to it. Work is pulled from this work queue in a manner such that each item pulled can only be pulled once.","title":"Work Queues"},{"location":"core/work_queue/#work-queues","text":"A work queue is a queue created for each analysis module type registered with the system. These queues are filled with analysis requests that are generated when other analysis requests are processed by the system. Each analysis module type gets exactly one work queue associated to it. Work is pulled from this work queue in a manner such that each item pulled can only be pulled once.","title":"Work Queues"},{"location":"design/alerts/","text":"Alerts \u00b6 When the ACE core system processes a root analysis that contains one or more detection points , it passes the root object to the alerting interface which then submits the alert to a place where analysts can manually review and disposition them.","title":"Alerts"},{"location":"design/alerts/#alerts","text":"When the ACE core system processes a root analysis that contains one or more detection points , it passes the root object to the alerting interface which then submits the alert to a place where analysts can manually review and disposition them.","title":"Alerts"},{"location":"design/analysis/","text":"Analysis \u00b6 An analysis is the output of the analysis of an observable . It consists of: zero or more observables a free form JSON formatted analysis output zero or more tags zero or more detection points The relationship between analysis and observable is always parent-child. Analysis Details \u00b6 The details of the analysis is simply free-form JSON-compatible data. This can be any value. The interpretation of this value is up to the python classes that implement the analysis modules and analysis objects. These details are stored separately from the JSON of the main root analysis object. They are loaded as needed. A brief summary of the details are stored instead.","title":"Analysis"},{"location":"design/analysis/#analysis","text":"An analysis is the output of the analysis of an observable . It consists of: zero or more observables a free form JSON formatted analysis output zero or more tags zero or more detection points The relationship between analysis and observable is always parent-child.","title":"Analysis"},{"location":"design/analysis/#analysis-details","text":"The details of the analysis is simply free-form JSON-compatible data. This can be any value. The interpretation of this value is up to the python classes that implement the analysis modules and analysis objects. These details are stored separately from the JSON of the main root analysis object. They are loaded as needed. A brief summary of the details are stored instead.","title":"Analysis Details"},{"location":"design/analysis_modes/","text":"Analysis Modes \u00b6 Analysis modes provide a way to logically group together different analysis modules and have them execute as a group. The analysis mode is a property of a root analysis object that determines what set of analysis modules (might) execute on observables in the object. Analysis modes are created by having analysis module types specify them in their list of constraints and requirements. Any analysis module can change the analysis mode of a root analysis object, which will in turn change what analysis modules continue to be executed against it.","title":"Analysis Modes"},{"location":"design/analysis_modes/#analysis-modes","text":"Analysis modes provide a way to logically group together different analysis modules and have them execute as a group. The analysis mode is a property of a root analysis object that determines what set of analysis modules (might) execute on observables in the object. Analysis modes are created by having analysis module types specify them in their list of constraints and requirements. Any analysis module can change the analysis mode of a root analysis object, which will in turn change what analysis modules continue to be executed against it.","title":"Analysis Modes"},{"location":"design/analysis_module/","text":"Analysis Module \u00b6 An analysis module is what takes an observable and generates analysis as output. Analysis modules execute in parallel to the core system. The modules that are part of the base installation are documented here .","title":"Analysis Module"},{"location":"design/analysis_module/#analysis-module","text":"An analysis module is what takes an observable and generates analysis as output. Analysis modules execute in parallel to the core system. The modules that are part of the base installation are documented here .","title":"Analysis Module"},{"location":"design/detection_points/","text":"Detection Points \u00b6 A detection point represents something determined to be suspicious enough to warrant investigation. Only observables and analysis objects can have detection points, and in practice, observables are usually the best place to put them. A entire analysis that has one or more detection points is considered by ACE to be an alert and thus has the analysis mode changed to correlation during analysis.","title":"Detection Points"},{"location":"design/detection_points/#detection-points","text":"A detection point represents something determined to be suspicious enough to warrant investigation. Only observables and analysis objects can have detection points, and in practice, observables are usually the best place to put them. A entire analysis that has one or more detection points is considered by ACE to be an alert and thus has the analysis mode changed to correlation during analysis.","title":"Detection Points"},{"location":"design/directives/","text":"Directives \u00b6 A directive is an additional analysis instruction given to an observable . Directives are typically used by analysis modules to control how they are treated by the analysis module. An observable can have zero or more directives.","title":"Directives"},{"location":"design/directives/#directives","text":"A directive is an additional analysis instruction given to an observable . Directives are typically used by analysis modules to control how they are treated by the analysis module. An observable can have zero or more directives.","title":"Directives"},{"location":"design/example_flow/","text":"Example Flow \u00b6 Let's follow a simple example to show how an alert gets created by ACE. In this example, we register analysis modules specifically to look for malicious word documents. Then we assume a sensor submits a word document for analysis. Register Analysis Modules \u00b6 Analysis modules process observables to see if an alert should be created. In this example we register two analysis modules: File Type analysis module This module accepts \" file \" observable types and outputs the type of file. For example: PDF, Word Document, Email, etc. This module adds tags like word_doc , pdf , email , etc. depending on the file type analysis result. Word Document analysis module This module accepts \" file \" observables and outputs if the word document is malicious. Additionally, it depends on the File Type module to determine if a file is malicious or not. This module may also add more observables like URLs from within the document, screenshots of the document content, etc. Analysis Module Queues and Mapping \u00b6 ACE receives the registration requests from the analysis modules and creates a queue dedicated to each. Analysis Submission \u00b6 A sensor submits a root analysis which contains an observable with type \" file .\" ACE keeps track of the root analysis and adds analysis module results throughout the lifetime of the root analysis. ACE then creates observable analysis requests for each observable within the root analysis and places them in the appropriate queue(s) for analysis modules that accept \" file \" observable types. In this case, we only have one observable. Handling Analysis Module Results \u00b6 The File Type analysis module receives the analysis request through its queue and then posts analysis results back to ACE. These results may include things like tags , directives , detection points , more observables, etc. ACE adds the analysis result to the root analysis, and then places any additional observables discovered by the analysis module into the appropriate queue(s) for further analysis. An Alert Is Born \u00b6 The Word Document analysis module found a Visual Basic macro that contained a function known to make network calls. This is suspicious and worth being presented to a security analyst. The Word Document analysis module adds a detection point to note that it has detected something that should be manually reviewed by an analyst. Once the analysis is submitted back to ACE, ACE adds the analysis to the root analysis object. ACE sees there is a detection point and will submit the root analysis as an alert.","title":"Example Flow"},{"location":"design/example_flow/#example-flow","text":"Let's follow a simple example to show how an alert gets created by ACE. In this example, we register analysis modules specifically to look for malicious word documents. Then we assume a sensor submits a word document for analysis.","title":"Example Flow"},{"location":"design/example_flow/#register-analysis-modules","text":"Analysis modules process observables to see if an alert should be created. In this example we register two analysis modules: File Type analysis module This module accepts \" file \" observable types and outputs the type of file. For example: PDF, Word Document, Email, etc. This module adds tags like word_doc , pdf , email , etc. depending on the file type analysis result. Word Document analysis module This module accepts \" file \" observables and outputs if the word document is malicious. Additionally, it depends on the File Type module to determine if a file is malicious or not. This module may also add more observables like URLs from within the document, screenshots of the document content, etc.","title":"Register Analysis Modules"},{"location":"design/example_flow/#analysis-module-queues-and-mapping","text":"ACE receives the registration requests from the analysis modules and creates a queue dedicated to each.","title":"Analysis Module Queues and Mapping"},{"location":"design/example_flow/#analysis-submission","text":"A sensor submits a root analysis which contains an observable with type \" file .\" ACE keeps track of the root analysis and adds analysis module results throughout the lifetime of the root analysis. ACE then creates observable analysis requests for each observable within the root analysis and places them in the appropriate queue(s) for analysis modules that accept \" file \" observable types. In this case, we only have one observable.","title":"Analysis Submission"},{"location":"design/example_flow/#handling-analysis-module-results","text":"The File Type analysis module receives the analysis request through its queue and then posts analysis results back to ACE. These results may include things like tags , directives , detection points , more observables, etc. ACE adds the analysis result to the root analysis, and then places any additional observables discovered by the analysis module into the appropriate queue(s) for further analysis.","title":"Handling Analysis Module Results"},{"location":"design/example_flow/#an-alert-is-born","text":"The Word Document analysis module found a Visual Basic macro that contained a function known to make network calls. This is suspicious and worth being presented to a security analyst. The Word Document analysis module adds a detection point to note that it has detected something that should be manually reviewed by an analyst. Once the analysis is submitted back to ACE, ACE adds the analysis to the root analysis object. ACE sees there is a detection point and will submit the root analysis as an alert.","title":"An Alert Is Born"},{"location":"design/observable/","text":"Observables \u00b6 An observable represents an observation made during the course of analysis. It always has a type and a value , and, optionally, has a time at which the observation was made. If the observable is missing the time, then the time is assumed to be the time of the entire event that is being analyzed. Observables are always children of analysis -based objects. Observables are analyzed by analysis modules which generate analysis as output. The newly created analysis can also contain more observables. Observables are unique according to their type, value, and time. If an observable with the same type, value, and time as another existing observable is added, it references the existing observable instead of creating a new one. Note that observables are unique by time. You can optionally group them together by time if you need to. Tagging \u00b6 An observable can have zero or more tags . Tagging is used to tie some concept, idea or grouping property to the observables. Directives \u00b6 An observable can have zero or more directives . Directives are used to give analysis modules some additional instructions on how to handle the observable. Redirection \u00b6 An observable can include a redirection , which points to another observable. Redirections are often used when extracting artifacts from files. They give ACE the ability to say \"This file actually came from this other file.\" A common example usage of this feature is determining which file to send to a sandboxing system. If a file was generated as part of an analysis, redirection can be used to point to the original file, giving the sandbox analysis module the correct file to analyze. Linking \u00b6 Linking occurs when an observable can be linked to another observable. Any tags applied to the original observable are also applied to the linked observable. Limited Analysis \u00b6 Given an observable, a limited analysis results from limiting what analysis modules are allowed to execute against it. This occurs by specifying one or more analysis modules as the limited analysis for an observable. Only modules in the specified list will be executed against such observable, and only if the module accepts the observable. Excluded Analysis \u00b6 An observable can restrict what analysis modules are executed against it by specifying one or more analysis modules as excluded analysis . Modules in the excluded analysis list are excluded from analyzing the observable. These modules will not execute against the observable regardless of any other condition. Relationships \u00b6 An observable can have a relationship to another observable. This has meaning only to analysis modules that utilized these relationships. Grouping by Time \u00b6 Observables can be grouped together for analysis purposes by time. This allows multiple observations over some time period to be treated as a single observation. For example, if the same IP address was observed 50 times over 5 seconds, they can be grouped into a single observation over that 5 second time period. Analysis \u00b6 An observable can have zero or more analysis objects attached to it. These represent the analysis performed by analysis modules .","title":"Observables"},{"location":"design/observable/#observables","text":"An observable represents an observation made during the course of analysis. It always has a type and a value , and, optionally, has a time at which the observation was made. If the observable is missing the time, then the time is assumed to be the time of the entire event that is being analyzed. Observables are always children of analysis -based objects. Observables are analyzed by analysis modules which generate analysis as output. The newly created analysis can also contain more observables. Observables are unique according to their type, value, and time. If an observable with the same type, value, and time as another existing observable is added, it references the existing observable instead of creating a new one. Note that observables are unique by time. You can optionally group them together by time if you need to.","title":"Observables"},{"location":"design/observable/#tagging","text":"An observable can have zero or more tags . Tagging is used to tie some concept, idea or grouping property to the observables.","title":"Tagging"},{"location":"design/observable/#directives","text":"An observable can have zero or more directives . Directives are used to give analysis modules some additional instructions on how to handle the observable.","title":"Directives"},{"location":"design/observable/#redirection","text":"An observable can include a redirection , which points to another observable. Redirections are often used when extracting artifacts from files. They give ACE the ability to say \"This file actually came from this other file.\" A common example usage of this feature is determining which file to send to a sandboxing system. If a file was generated as part of an analysis, redirection can be used to point to the original file, giving the sandbox analysis module the correct file to analyze.","title":"Redirection"},{"location":"design/observable/#linking","text":"Linking occurs when an observable can be linked to another observable. Any tags applied to the original observable are also applied to the linked observable.","title":"Linking"},{"location":"design/observable/#limited-analysis","text":"Given an observable, a limited analysis results from limiting what analysis modules are allowed to execute against it. This occurs by specifying one or more analysis modules as the limited analysis for an observable. Only modules in the specified list will be executed against such observable, and only if the module accepts the observable.","title":"Limited Analysis"},{"location":"design/observable/#excluded-analysis","text":"An observable can restrict what analysis modules are executed against it by specifying one or more analysis modules as excluded analysis . Modules in the excluded analysis list are excluded from analyzing the observable. These modules will not execute against the observable regardless of any other condition.","title":"Excluded Analysis"},{"location":"design/observable/#relationships","text":"An observable can have a relationship to another observable. This has meaning only to analysis modules that utilized these relationships.","title":"Relationships"},{"location":"design/observable/#grouping-by-time","text":"Observables can be grouped together for analysis purposes by time. This allows multiple observations over some time period to be treated as a single observation. For example, if the same IP address was observed 50 times over 5 seconds, they can be grouped into a single observation over that 5 second time period.","title":"Grouping by Time"},{"location":"design/observable/#analysis","text":"An observable can have zero or more analysis objects attached to it. These represent the analysis performed by analysis modules .","title":"Analysis"},{"location":"design/root_analysis/","text":"Root Analysis \u00b6 The analysis --> observable --> analysis relationship forms a hierarchical tree with a special analysis object called the root analysis as the starting point of the tree. A root analysis is a special type of analysis object that contains additional information about the analysis as a whole, such as, what generated it, description information, instructions for analysts, etc... A root analysis can become an alert if one or more detection points are added during the course of analysis.","title":"Root Analysis"},{"location":"design/root_analysis/#root-analysis","text":"The analysis --> observable --> analysis relationship forms a hierarchical tree with a special analysis object called the root analysis as the starting point of the tree. A root analysis is a special type of analysis object that contains additional information about the analysis as a whole, such as, what generated it, description information, instructions for analysts, etc... A root analysis can become an alert if one or more detection points are added during the course of analysis.","title":"Root Analysis"},{"location":"design/tags/","text":"Tags \u00b6 Tagging is a way to add additional information or context to analysis data. Tags can also be used to add relationships between different root analysis objects. Only observables and analysis can be tagged. In practice, observables are usually what get tagged. Tagging shows up in the GUI as labels of varying colors. The value of a tag is any UTF8 encoded string.","title":"Tags"},{"location":"design/tags/#tags","text":"Tagging is a way to add additional information or context to analysis data. Tags can also be used to add relationships between different root analysis objects. Only observables and analysis can be tagged. In practice, observables are usually what get tagged. Tagging shows up in the GUI as labels of varying colors. The value of a tag is any UTF8 encoded string.","title":"Tags"},{"location":"development/caching/","text":"","title":"Caching"},{"location":"development/system/","text":"Core System \u00b6 Global System Reference \u00b6 The core system is composed of subsystems that implement some required features of ACE. The full contract of the entire system is found here . A reference to the global instance of the core system can be obtained by calling ace.system.get_system() . The properties of this object are references to implementations of the subsystem interfaces. For example: from ace.system import get_system # obtain a reference to the analysis tracking subsystem get_system().analysis_tracking Core API \u00b6 The core API is the set of function calls made available by all of the subsystem interfaces. There are two sets of API functions: interface and module . The module API is the full ACE core API . Interface API Functions \u00b6 Each subsystem interface defines what functions needs to be implemented. For example: class AlertTrackingInterface(ACESystemInterface): \"\"\"Tracks alerts as they are detected during the processing of analysis requests.\"\"\" def track_alert(self, root: RootAnalysis) -> Any: raise NotImplementedError() def get_alert(self, id: str) -> Union[Any, None]: raise NotImplementedError() To call the track_alert function using the interface API, we would do the following: get_system().alerting.track_alert(root) In this code we: obtain a reference to the core system with get_system() obtain a reference to the alert tracking subsystem with .alerting call the track_alert interface API function Module API Functions \u00b6 The interface API functions are wrapped by functions defined at the module level. The functions provide additional functionality such as: error and type checking parameter casting logging Outside of subsystem interface development, it is better to use the module API functions to interact with the core system. For example, ace.system.analysis_tracking.AnalysisTrackingInterface defines the get_root_analysis function, which could be called like this: root = get_system().analysis_tracking.get_root_analysis(uuid) It is recommended to call the same function like this: from ace.system.analysis_tracking import get_root_analysis root = get_root_analysis(uuid) There are module API functions that do not have corresponding interface API functions, but they may be composed of them. For example, ace.system.work_queue.get_next_analysis_request has no corresponding interface API function, but is composed of calls to multiple interface API functions. Summary \u00b6 ACE core is composed of subsystems referenced by get_system() . Each subsystem defines interface API functions, which are wrapped by module API functions. The entire ACE core API is the full set of module API functions.","title":"Core System"},{"location":"development/system/#core-system","text":"","title":"Core System"},{"location":"development/system/#global-system-reference","text":"The core system is composed of subsystems that implement some required features of ACE. The full contract of the entire system is found here . A reference to the global instance of the core system can be obtained by calling ace.system.get_system() . The properties of this object are references to implementations of the subsystem interfaces. For example: from ace.system import get_system # obtain a reference to the analysis tracking subsystem get_system().analysis_tracking","title":"Global System Reference"},{"location":"development/system/#core-api","text":"The core API is the set of function calls made available by all of the subsystem interfaces. There are two sets of API functions: interface and module . The module API is the full ACE core API .","title":"Core API"},{"location":"development/system/#interface-api-functions","text":"Each subsystem interface defines what functions needs to be implemented. For example: class AlertTrackingInterface(ACESystemInterface): \"\"\"Tracks alerts as they are detected during the processing of analysis requests.\"\"\" def track_alert(self, root: RootAnalysis) -> Any: raise NotImplementedError() def get_alert(self, id: str) -> Union[Any, None]: raise NotImplementedError() To call the track_alert function using the interface API, we would do the following: get_system().alerting.track_alert(root) In this code we: obtain a reference to the core system with get_system() obtain a reference to the alert tracking subsystem with .alerting call the track_alert interface API function","title":"Interface API Functions"},{"location":"development/system/#module-api-functions","text":"The interface API functions are wrapped by functions defined at the module level. The functions provide additional functionality such as: error and type checking parameter casting logging Outside of subsystem interface development, it is better to use the module API functions to interact with the core system. For example, ace.system.analysis_tracking.AnalysisTrackingInterface defines the get_root_analysis function, which could be called like this: root = get_system().analysis_tracking.get_root_analysis(uuid) It is recommended to call the same function like this: from ace.system.analysis_tracking import get_root_analysis root = get_root_analysis(uuid) There are module API functions that do not have corresponding interface API functions, but they may be composed of them. For example, ace.system.work_queue.get_next_analysis_request has no corresponding interface API function, but is composed of calls to multiple interface API functions.","title":"Module API Functions"},{"location":"development/system/#summary","text":"ACE core is composed of subsystems referenced by get_system() . Each subsystem defines interface API functions, which are wrapped by module API functions. The entire ACE core API is the full set of module API functions.","title":"Summary"},{"location":"development/system/concurrency/","text":"Concurrency \u00b6 The core system is designed in such a way that each subsystem can execute independently from the other. A distributed locking system is available to serialize multiple concurrent modification requests to the same object. Concurrent Modification Restrictions \u00b6 The core system must resolve concurrent requests to satisfy analysis results. Analysis results can contain side effects . This makes result resolution challenging. Consider the following scenario: root analysis object Z 1 contains observable O 1 . Two different analysis modules A 1 and A 2 are registered to analyze O 1 . Both analysis modules operate independently. A 2 finishes first adding an analysis result R 2 to O 1 and adding a tag T 1 to O 1 . Adding the tag is a side effect . A 1 finishes second and adds analysis result R 1 to O 1 but does not add a tag. Due to the side effect, the core system cannot simply replace O 1 when it resolves R 1 because it would overwrite it without the tag that A 2 added to it. The core system instead merges the results together. Merging \u00b6 Merging allows one object to be merged into another. There are two types of merging in the core system: direct and differential . Python classes that support merging will have apply_merge and apply_diff_merge functions. Direct Merge \u00b6 A direct merge takes the form of target.apply_merge(source) and copies anything in source that is not in target . In our previous example, a direct merge of R 1 into O 1 would preserve T 1 because it would only add the analysis result R 1 and do nothing else. Likewise, if R 1 finished first, then a direct merge of R 2 O 1 would add T 1 into O 1 because T 1 does not exist in the target. There is another scenario that requires additional logic to handle. Consider the following: root analysis object Z 1 contains observable O 1 . Two different analysis modules A 1 and A 2 are registered to analyze O 1 . Both analysis modules operate independently. A 1 finishes first and adds analysis result R 1 to O 1 , but also changes the analysis_mode property of Z 1 from analysis to correlation . This change to Z 1 is a side effect . A 2 finishes second and adds analysis result R 2 to O 1 . However, it does not change the analysis_mode property of Z 1 . At this point, the core system has no idea if A 2 left the property alone or if it changed it back . Differential Merge \u00b6 A differential merge applies the changes (delta) between two objects to a target object. It takes the form of target.apply_diff_merge(before, after) where target is the object to receive the changes, before is the state of the object before the changes were made, and after is the state of the object after the changes were made. If we apply this to the previous scenario, the differential merge would see that the analysis_mode property was the same in both the before and after objects, so R 2 would not overwrite the property with the wrong value.","title":"Concurrency"},{"location":"development/system/concurrency/#concurrency","text":"The core system is designed in such a way that each subsystem can execute independently from the other. A distributed locking system is available to serialize multiple concurrent modification requests to the same object.","title":"Concurrency"},{"location":"development/system/concurrency/#concurrent-modification-restrictions","text":"The core system must resolve concurrent requests to satisfy analysis results. Analysis results can contain side effects . This makes result resolution challenging. Consider the following scenario: root analysis object Z 1 contains observable O 1 . Two different analysis modules A 1 and A 2 are registered to analyze O 1 . Both analysis modules operate independently. A 2 finishes first adding an analysis result R 2 to O 1 and adding a tag T 1 to O 1 . Adding the tag is a side effect . A 1 finishes second and adds analysis result R 1 to O 1 but does not add a tag. Due to the side effect, the core system cannot simply replace O 1 when it resolves R 1 because it would overwrite it without the tag that A 2 added to it. The core system instead merges the results together.","title":"Concurrent Modification Restrictions"},{"location":"development/system/concurrency/#merging","text":"Merging allows one object to be merged into another. There are two types of merging in the core system: direct and differential . Python classes that support merging will have apply_merge and apply_diff_merge functions.","title":"Merging"},{"location":"development/system/concurrency/#direct-merge","text":"A direct merge takes the form of target.apply_merge(source) and copies anything in source that is not in target . In our previous example, a direct merge of R 1 into O 1 would preserve T 1 because it would only add the analysis result R 1 and do nothing else. Likewise, if R 1 finished first, then a direct merge of R 2 O 1 would add T 1 into O 1 because T 1 does not exist in the target. There is another scenario that requires additional logic to handle. Consider the following: root analysis object Z 1 contains observable O 1 . Two different analysis modules A 1 and A 2 are registered to analyze O 1 . Both analysis modules operate independently. A 1 finishes first and adds analysis result R 1 to O 1 , but also changes the analysis_mode property of Z 1 from analysis to correlation . This change to Z 1 is a side effect . A 2 finishes second and adds analysis result R 2 to O 1 . However, it does not change the analysis_mode property of Z 1 . At this point, the core system has no idea if A 2 left the property alone or if it changed it back .","title":"Direct Merge"},{"location":"development/system/concurrency/#differential-merge","text":"A differential merge applies the changes (delta) between two objects to a target object. It takes the form of target.apply_diff_merge(before, after) where target is the object to receive the changes, before is the state of the object before the changes were made, and after is the state of the object after the changes were made. If we apply this to the previous scenario, the differential merge would see that the analysis_mode property was the same in both the before and after objects, so R 2 would not overwrite the property with the wrong value.","title":"Differential Merge"},{"location":"development/system/serialization/","text":"Serialization \u00b6 Data is tracked by the core system in JSON format. The schema of the JSON data is defined in ace/data_model.py by using the pydantic library. The data model is separate from the classes that use them. Each class defined here has a corresponding class. For example, ace.data_model.DetectionPointModel is the data model for ace.analysis.DetectionPoint . The models are used to translate between Python objects, JSON strings, and vice versa. Every Python class that has a corresponding data model defines a to_dict() and to_json() function, as well as class methods for from_dict() and from_json() . The JSON encoder defined for the pydantic library is used to encode and decode complex data types such as dates. Therefore, always use the to_json() and from_json() functions to translate rather than using import json .","title":"Serialization"},{"location":"development/system/serialization/#serialization","text":"Data is tracked by the core system in JSON format. The schema of the JSON data is defined in ace/data_model.py by using the pydantic library. The data model is separate from the classes that use them. Each class defined here has a corresponding class. For example, ace.data_model.DetectionPointModel is the data model for ace.analysis.DetectionPoint . The models are used to translate between Python objects, JSON strings, and vice versa. Every Python class that has a corresponding data model defines a to_dict() and to_json() function, as well as class methods for from_dict() and from_json() . The JSON encoder defined for the pydantic library is used to encode and decode complex data types such as dates. Therefore, always use the to_json() and from_json() functions to translate rather than using import json .","title":"Serialization"},{"location":"development/system/subsystems/","text":"Core Subsystems \u00b6 Implementations \u00b6 The core library contains some default implementations of the subsystems for various usages. Threaded \u00b6 The threaded subsystem interfaces defined in ace.system.threaded are simple implementations that: assume the entire system runs in a single process under multiple threads tracks all data in in-memory data structures It is used for unit testing and one-off command line analysis. Database \u00b6 The database subsystem interfaces defined in ace.system.database are implementations that use SQLalchemy to track data. The schema of the database tables are defined in ace.database.schema . Distributed \u00b6 The distributed subsystem interfaces defined in ace.system.distributed are implementations that use FastAPI to expose the interfaces to external systems. The distributed subsystem can be used to implement a highly scalable ACE core system. Core Subsystem Composition \u00b6 The ACE core can be composed of any combination of subsystem implementations. They can be mixed in whatever combination is required. This is possible because each subsystem has no dependency on another except through the core system API.","title":"Core Subsystems"},{"location":"development/system/subsystems/#core-subsystems","text":"","title":"Core Subsystems"},{"location":"development/system/subsystems/#implementations","text":"The core library contains some default implementations of the subsystems for various usages.","title":"Implementations"},{"location":"development/system/subsystems/#threaded","text":"The threaded subsystem interfaces defined in ace.system.threaded are simple implementations that: assume the entire system runs in a single process under multiple threads tracks all data in in-memory data structures It is used for unit testing and one-off command line analysis.","title":"Threaded"},{"location":"development/system/subsystems/#database","text":"The database subsystem interfaces defined in ace.system.database are implementations that use SQLalchemy to track data. The schema of the database tables are defined in ace.database.schema .","title":"Database"},{"location":"development/system/subsystems/#distributed","text":"The distributed subsystem interfaces defined in ace.system.distributed are implementations that use FastAPI to expose the interfaces to external systems. The distributed subsystem can be used to implement a highly scalable ACE core system.","title":"Distributed"},{"location":"development/system/subsystems/#core-subsystem-composition","text":"The ACE core can be composed of any combination of subsystem implementations. They can be mixed in whatever combination is required. This is possible because each subsystem has no dependency on another except through the core system API.","title":"Core Subsystem Composition"}]}